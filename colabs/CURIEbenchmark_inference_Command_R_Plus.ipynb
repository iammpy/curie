{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGW0Oeb2IxMX"
   },
   "source": [
    "## Notebook for processesing CURIE-benchmark tasks using the **Cohere Command-R Plus model**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8rsiVfsTG-A-"
   },
   "outputs": [],
   "source": [
    "# @title Import Required Libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import altair as alt\n",
    "import logging\n",
    "import textwrap as tr\n",
    "import torch\n",
    "# from google.colab import drive\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, List\n",
    "from enum import Enum\n",
    "import concurrent.futures\n",
    "from model import call_huoshan,call_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYK7SbWtG-vu",
    "outputId": "bbef8713-ef2b-49c0-8590-c24cc8ca5216"
   },
   "outputs": [],
   "source": [
    "# # @title Install and import Cohere\n",
    "# ! pip install -U cohere\n",
    "# import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lw-KLn5zHFmx"
   },
   "outputs": [],
   "source": [
    "# # @title API Configuration\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "MODEL_PATH = 'command-r-plus'\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "# \"DeepSeek-R1-Distill-Qwen-7B\"\n",
    "# \"DeepSeek-R1-Distill-Qwen-32B\"\n",
    "# MODEL_NAME = \"deepseek-r1\"\n",
    "# \"doubao-1.5-thinking-pro\"\n",
    "# co_v2 = cohere.ClientV2(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ev-eMAHRHJl3",
    "outputId": "4d0f2a09-c59f-4868-e642-b01d5819a386"
   },
   "outputs": [],
   "source": [
    "# @title Mount Google Drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "# os.chdir(\"/content/drive/My Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jN6DcI1BIP-u"
   },
   "outputs": [],
   "source": [
    "# @title Configuration Classes\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configuration class for experiment settings\"\"\"\n",
    "    name: str\n",
    "    base_dir: str\n",
    "    inference_dir: str\n",
    "    prompt_path: str\n",
    "\n",
    "class ExperimentType(Enum):\n",
    "    \"\"\"Enum for different types of experiments\"\"\"\n",
    "    PDB = \"pdb\"\n",
    "    MPVE = \"mpve\"\n",
    "    HFE = \"hfe\"\n",
    "    GEO = \"geo\"\n",
    "    DFT = \"dft\"\n",
    "    HFD = \"hfd\"\n",
    "    QECC_PDF = \"qecc_pdf\"\n",
    "    QECC_TEX = \"qecc_tex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0K6ocK19G5GM"
   },
   "outputs": [],
   "source": [
    "# @title Experiment Manager Class\n",
    "class ExperimentManager:\n",
    "    \"\"\"Manages different experiment configurations\"\"\"\n",
    "    def __init__(self, base_path: str = \"..\"):\n",
    "        self.base_path = base_path\n",
    "        self.experiments = self._initialize_experiments()\n",
    "\n",
    "    def _initialize_experiments(self) -> Dict[ExperimentType, ExperimentConfig]:\n",
    "        \"\"\"Initialize all experiment configurations\"\"\"\n",
    "        benchmark_path = f\"{self.base_path}\"\n",
    "        return {\n",
    "            ExperimentType.PDB: ExperimentConfig(\n",
    "                name=\"PDB\",\n",
    "                base_dir=f\"{self.base_path}/pdb\",\n",
    "                inference_dir=f\"{self.base_path}/inference/multi_runs/current/pdb_new/reconstruct_protein_amino_acid_sequence_0_shot/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/reconstruct_protein_amino_acid_sequence_0_shot.txt\"\n",
    "            ),\n",
    "            ExperimentType.MPVE: ExperimentConfig(\n",
    "                name=\"MPVE\",\n",
    "                base_dir=f\"{benchmark_path}/data/mpve\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/mpve/mat_paper_to_property_1_shot_exclude_trivia/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/mat_paper_to_property_1_shot_exclude_trivia.txt\"\n",
    "            ),\n",
    "            ExperimentType.HFE: ExperimentConfig(\n",
    "                name=\"HFE\",\n",
    "                base_dir=f\"{benchmark_path}/data/hfe\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/hfe/extract_hamiltonian_0_shot/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/extract_hamiltonian_0_shot.txt\"\n",
    "            ),\n",
    "            ExperimentType.GEO: ExperimentConfig(\n",
    "                name=\"GEO\",\n",
    "                base_dir=f\"{benchmark_path}/data/geo\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/geo/extract_dataset_from_geo_papers_0_shot\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/extract_dataset_from_geo_papers_0_shot.txt\"\n",
    "            ),\n",
    "            ExperimentType.DFT: ExperimentConfig(\n",
    "                name=\"DFT\",\n",
    "                base_dir=f\"{benchmark_path}/data/dft\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/dft/extract_dft_metadata_1_shot/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/extract_dft_metadata_1_shot.txt\"\n",
    "            ),\n",
    "            ExperimentType.HFD: ExperimentConfig(\n",
    "                name=\"HFD\",\n",
    "                base_dir=f\"{benchmark_path}/data/hfd\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/hfd/derivation_prompt/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/derivation_prompt.txt\"\n",
    "            ),\n",
    "            ExperimentType.QECC_PDF: ExperimentConfig(\n",
    "                name=\"QECC_PDF\",\n",
    "                base_dir=f\"{benchmark_path}/data/qecc_pdf\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/qecc_pdf/describe_code_in_paper/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/describe_code_in_paper.txt\"\n",
    "            ),\n",
    "            ExperimentType.QECC_TEX: ExperimentConfig(\n",
    "                name=\"QECC_TEX\",\n",
    "                base_dir=f\"{benchmark_path}/data/qecc_tex\",\n",
    "                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/qecc_tex/describe_code_in_paper/\",\n",
    "                prompt_path=f\"{benchmark_path}/prompts/describe_code_in_paper.txt\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def get_config(self, experiment_type: ExperimentType) -> ExperimentConfig:\n",
    "        \"\"\"Get configuration for specific experiment type\"\"\"\n",
    "        return self.experiments[experiment_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "02DSqrzbHYUi"
   },
   "outputs": [],
   "source": [
    "# @title Paper Processing Utilities\n",
    "def specialize_prompt(template: str, tag: str, infil: str) -> str:\n",
    "    \"\"\"Replace a tag in a template with provided text.\"\"\"\n",
    "    if tag in template:\n",
    "        return template.replace(tag, infil)\n",
    "    raise ValueError(f'{tag} absent in template.')\n",
    "\n",
    "def prepare_task_for_paper(paper: str, config: ExperimentConfig, model_id: str) -> dict:\n",
    "    \"\"\"Prepare the task information for a given paper.\"\"\"\n",
    "    paper_input = os.path.join(config.base_dir, 'inputs', f'{paper}.json')\n",
    "    paper_gt = os.path.join(config.base_dir, 'ground_truth', f'{paper}.json')\n",
    "\n",
    "    with open(paper_input, 'r') as f:\n",
    "        inputs = json.load(f)\n",
    "    with open(paper_gt, 'r') as f:\n",
    "        targets = json.load(f)\n",
    "\n",
    "    with open(config.prompt_path, 'r') as f:\n",
    "        ptemp = f.read()\n",
    "\n",
    "    spec_prompt = specialize_prompt(ptemp, '{{text}}', infil=inputs['text'])\n",
    "\n",
    "    return {\n",
    "        'record_id': paper,\n",
    "        'model_id': MODEL_NAME,\n",
    "        'prompt_path': config.prompt_path,\n",
    "        'prompt_text': spec_prompt,\n",
    "        \n",
    "        'reasoning_content':'',\n",
    "        'response_text': ''\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vslgWfVSHQR0"
   },
   "outputs": [],
   "source": [
    "# @title Paper Processor Class\n",
    "class PaperProcessor:\n",
    "    \"\"\"Handles the processing of scientific papers\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model_path: str):\n",
    "        # self.co_v2 = cohere.ClientV2(api_key=api_key)\n",
    "        self.model_path = model_path\n",
    "        self._setup_logging()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configure logging settings\"\"\"\n",
    "        logging.basicConfig(\n",
    "            filename='experiment_log.log',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential(multiplier=1, min=4, max=10),\n",
    "        reraise=True\n",
    "    )\n",
    "    def _make_api_call(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"Make API call with retry logic\"\"\"\n",
    "        response = self.co_v2.chat(\n",
    "            model=self.model_path,\n",
    "            messages=messages,\n",
    "            temperature=0.9,\n",
    "            k=50,\n",
    "            p=0.95,\n",
    "            max_tokens=4000\n",
    "        )\n",
    "        return self._extract_response_text(response)\n",
    "\n",
    "    def _extract_response_text(self, response) -> str:\n",
    "        \"\"\"Extract text from API response\"\"\"\n",
    "        if hasattr(response, 'message'):\n",
    "            if hasattr(response.message, 'content'):\n",
    "                if isinstance(response.message.content, list):\n",
    "                    return ' '.join(item.text for item in response.message.content if hasattr(item, 'text'))\n",
    "                elif isinstance(response.message.content, str):\n",
    "                    return response.message.content\n",
    "        return str(response)\n",
    "\n",
    "    def _save_result(self, task_info: dict, inference_dir: str, run_id: int, success: bool = True):\n",
    "        \"\"\"Save processing results\"\"\"\n",
    "        status = 'success' if success else 'failure'\n",
    "        output_dir = os.path.join(inference_dir, MODEL_NAME, f'run_{run_id}', status)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        serializable_task_info = {\n",
    "            'record_id': task_info['record_id'],\n",
    "            'model_id': task_info['model_id'],\n",
    "            'prompt_path': task_info['prompt_path'],\n",
    "            'reasoning_content': task_info['reasoning_content'],\n",
    "            'prompt_text': task_info['prompt_text'],\n",
    "            'response_text': str(task_info['response_text'])\n",
    "        }\n",
    "\n",
    "        output_file = os.path.join(output_dir, f'{task_info[\"record_id\"]}.json')\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(serializable_task_info, f, indent=4,ensure_ascii=False)\n",
    "\n",
    "    def process_papers(self, config: ExperimentConfig, run_range: range = range(1, 2)):\n",
    "        \"\"\"Process papers for given experiment configuration\"\"\"\n",
    "        input_dir = os.path.join(config.base_dir, 'inputs')\n",
    "        papers = [f.replace('.json', '') for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "        self.logger.info(f\"Starting processing {len(papers)} papers for {config.name}\")\n",
    "\n",
    "        for run_id in run_range:\n",
    "            self.logger.info(f\"Starting run {run_id + 1}\")\n",
    "            print(f\"Starting run {run_id + 1}\")\n",
    "            # for i, paper in enumerate(papers, 1):\n",
    "            #     self.logger.info(f\"Processing paper {i}/{len(papers)} in run {run_id + 1}\")\n",
    "            #     self._process_single_paper(paper, config, run_id)\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "                # 提交所有任务\n",
    "                future_to_paper = {\n",
    "                    executor.submit(self._process_single_paper, paper, config, run_id): paper\n",
    "                    for paper in papers\n",
    "                }\n",
    "\n",
    "                processed_count = 0\n",
    "                for future in concurrent.futures.as_completed(future_to_paper):\n",
    "                    paper_name = future_to_paper[future]\n",
    "                    processed_count += 1\n",
    "                    try:\n",
    "                        # 获取结果，如果任务中发生未捕获的异常，这里会重新抛出\n",
    "                        # _process_single_paper 内部已经有异常处理和日志记录，所以这里通常不会抛出\n",
    "                        future.result()\n",
    "                        # 在这里记录成功完成\n",
    "                        self.logger.info(f\"Completed processing for paper {paper_name} ({processed_count}/{len(papers)}) in run {run_id + 1}.\")\n",
    "                        print(f\"Completed processing for paper {paper_name} ({processed_count}/{len(papers)}) in run {run_id + 1}.\")\n",
    "                    except Exception as exc:\n",
    "                        # 这个异常通常不应该发生，因为 _process_single_paper 内部会捕获\n",
    "                        self.logger.error(f\"An unexpected error occurred for paper {paper_name} in run {run_id + 1} during future processing: {exc}\")\n",
    "            \n",
    "            self.logger.info(f\"Finished run {run_id + 1}.\")\n",
    "\n",
    "        self.logger.info(f\"All runs completed for {config.name}.\")\n",
    "\n",
    "    def _process_single_paper(self, paper: str, config: ExperimentConfig, run_id: int):\n",
    "        \"\"\"Process a single paper\"\"\"\n",
    "        try:\n",
    "            task_info = prepare_task_for_paper(paper, config, self.model_path)\n",
    "\n",
    "            if len(task_info['prompt_text'].split()) > 128000:\n",
    "                raise ValueError(\"Input text exceeds token limit\")\n",
    "\n",
    "            # response = self._make_api_call([{\n",
    "            #     \"role\": \"user\",\n",
    "            #     \"content\": task_info['prompt_text']\n",
    "            # }])\n",
    "            # print(f\"Processing paper {paper} \")\n",
    "            # task_info['prompt_text'] = '你是谁' # 4000 tokens\n",
    "            if MODEL_NAME == \"DeepSeek-R1-Distill-Qwen-7B\" or MODEL_NAME == \"DeepSeek-R1-Distill-Qwen-32B\":\n",
    "                reasoning_content, response = call_server(messages=task_info['prompt_text'],\n",
    "                                                          model_name=MODEL_NAME)\n",
    "            elif MODEL_NAME == \"doubao-1.5-thinking-pro\" or MODEL_NAME == \"deepseek-r1\":\n",
    "                reasoning_content, response = call_huoshan([{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": task_info['prompt_text']\n",
    "                }], model_name=MODEL_NAME)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model name: {MODEL_NAME}\")\n",
    "            print(f\"paper {paper} finished, response: {response[:100]}...\",end='')\n",
    "            task_info['record_id'] = paper\n",
    "            task_info['reasoning_content'] = reasoning_content\n",
    "        \n",
    "            task_info['response_text'] = response\n",
    "            self._save_result(task_info, config.inference_dir, run_id, success=True)\n",
    "            # time.sleep(2)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing paper {paper}: {str(e)}\")\n",
    "            task_info['response_text'] = str(e)\n",
    "            self._save_result(task_info, config.inference_dir, run_id, success=False)\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "GVSZxHWAHSRm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n",
      "paper 137261967 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"Ni-doped TiO<sub>2<\\/sub>\",\n",
      "    \"material_descriptor\": \"thin film\\nchemical...Completed processing for paper 137261967 (1/17) in run 2.\n",
      "paper 68518 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"CdO\",\n",
      "    \"material_descriptor\": \"single-crystalline nanowires\\nsynthesized...Completed processing for paper 68518 (2/17) in run 2.\n",
      "paper 11181068 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"Si NCs\",\n",
      "    \"material_descriptor\": \"synthesized through a non-thermal plas...Completed processing for paper 11181068 (3/17) in run 2.\n",
      "paper 137362119 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"CoFe<sub>2</sub>O<sub>4</sub> nanoparticles\",\n",
      "    \"material_descriptor\": \"s...Completed processing for paper 137362119 (4/17) in run 2.\n",
      "paper 15804005 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"HfO<sub>2<\\/sub>\",\n",
      "    \"material_descriptor\": \"pure HfO<sub>2<\\/sub> film\",...Completed processing for paper 15804005 (5/17) in run 2.\n",
      "paper 53519111 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"ZnO\",\n",
      "    \"material_descriptor\": \"II-VI semiconductor\\nwurtzite lattice\",\n",
      " ...Completed processing for paper 53519111 (6/17) in run 2.\n",
      "paper 12841719 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"Si carbide\",\n",
      "    \"material_descriptor\": \"dielectric matrix\",\n",
      "    \"material_...Completed processing for paper 12841719 (7/17) in run 2.\n",
      "paper 6183251 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"a-Si<sub>1-x<\\/sub>C<sub>x<\\/sub>\",\n",
      "    \"material_descriptor\": \"passivation...Completed processing for paper 6183251 (8/17) in run 2.\n",
      "paper 2837337 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"silicon\",\n",
      "    \"material_descriptor\": \"\",\n",
      "    \"material_source_passage\": \"Tr...Completed processing for paper 2837337 (9/17) in run 2.\n",
      "paper 97574650 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"CdO\",\n",
      "    \"material_descriptor\": \"n-type semiconductor\",\n",
      "    \"material_sour...Completed processing for paper 97574650 (10/17) in run 2.\n",
      "paper 17645319 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"ZnO nanowires\",\n",
      "    \"material_descriptor\": \"catalyst-free high-quality\",\n",
      "  ...Completed processing for paper 17645319 (11/17) in run 2.\n",
      "paper 135893324 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"CuInSe<sub>2</sub>\",\n",
      "    \"material_descriptor\": \"thin films\",\n",
      "    \"material...Completed processing for paper 135893324 (12/17) in run 2.\n",
      "paper 11093908 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"InN\",\n",
      "    \"material_descriptor\": \"III-N compound for near-infrared optoelec...Completed processing for paper 11093908 (13/17) in run 2.\n",
      "paper 10222315 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"ZnO micro/nanotubes\",\n",
      "    \"material_descriptor\": \"aligned\\nsynthesized on z...Completed processing for paper 10222315 (14/17) in run 2.\n",
      "paper 55005437 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"ZnSe\",\n",
      "    \"material_descriptor\": \"\",\n",
      "    \"material_source_passage\": \"ZnSe ...Completed processing for paper 55005437 (15/17) in run 2.\n",
      "paper 53384093 finished, response: \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"material\": \"Ni<sub>x</sub>W<sub>1−x</sub> oxide\",\n",
      "    \"material_descriptor\": \"films, re...Completed processing for paper 53384093 (16/17) in run 2.\n"
     ]
    }
   ],
   "source": [
    "# @title Main Execution\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    experiment_manager = ExperimentManager()\n",
    "\n",
    "    processor = PaperProcessor(\n",
    "        api_key=API_KEY,\n",
    "        model_path=MODEL_PATH\n",
    "    )\n",
    "\n",
    "    # Select experiment type\n",
    "    # experiment_type = ExperimentType.MPVE  # CHANGE THIS to process different experiments\n",
    "    experiment_type = ExperimentType.MPVE\n",
    "    config = experiment_manager.get_config(experiment_type)\n",
    "\n",
    "    processor.process_papers(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
